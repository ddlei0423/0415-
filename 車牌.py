# -*- coding: utf-8 -*-
"""車牌

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ZhvW1nJPNmSemGV5X53mXFI6PGf4Ka4M
"""

import os
import cv2
import numpy as np
import csv

extension = '.jpg'
imagePath = '0808-GY.jpg'
patternsPath = 'solid_patterns/'
databasePath = 'car_owners.csv'  # 資料庫檔案路徑

# 取出車牌 Getting License Plate
rawImage = cv2.cvtColor(np.array(cv2.imread(imagePath)), cv2.COLOR_RGB2BGR)
contours, hierarchy = cv2.findContours(cv2.Canny(cv2.GaussianBlur(cv2.bilateralFilter(cv2.cvtColor(rawImage, cv2.COLOR_BGR2GRAY), 11, 17, 17), (5, 5), 0), 170, 200), cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)  # 轉為灰階，去除背景雜訊，高斯模糊，取得邊緣，取得輪廓
rectangleContours = []  # 為四邊形的集合
for contour in sorted(contours, key=cv2.contourArea, reverse=True)[:30]:  # 只取前三十名輪廓
    if len(cv2.approxPolyDP(contour, 0.02 * cv2.arcLength(contour, True), True)) == 4:  # 取得輪廓周長*0.02(越小，得到的多邊形角點越多)後，得到多邊形角點，為四邊形者
        rectangleContours.append(contour)
x, y, w, h = cv2.boundingRect(rectangleContours[0])  # 只取第一名，用一個最小的四邊形，把找到的輪廓包起來。
ret, plateImage = cv2.threshold(cv2.cvtColor(cv2.GaussianBlur(rawImage[y:y + h, x:x + w], (3, 3), 0), cv2.COLOR_RGB2GRAY), 0, 255, cv2.THRESH_OTSU)  # 找到車牌後，由原來的圖截取出來，再將其高斯模糊以及取得灰階，再獲得Binary圖

# 取出車牌文字 Getting License Plate Number
contours, hierarchy = cv2.findContours(plateImage, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)  # 取得車牌文字輪廓
letters = []
for contour in contours:  # 遍歷取得的輪廓
    rect = cv2.boundingRect(contour)
    if (rect[3] > (rect[2] * 1.5)) and (rect[3] < (rect[2] * 3.5) and (rect[2] > 10)):  # 過濾雜輪廓
        letters.append(cv2.boundingRect(contour))  # 存入過濾過的輪廓
letter_images = []
for letter in sorted(letters, key=lambda s: s[0], reverse=False):  # 重新安排號碼順序遍歷
    letter_images.append(plateImage[letter[1]:letter[1] + letter[3], letter[0]:letter[0] + letter[2]])  # 將過濾過的輪廓使用原圖裁切
# show文字裁切成果(可選) Showing License Plate Number (optional)
from matplotlib import pyplot as plt
for i, j in enumerate(letter_images):
    plt.subplot(1, len(letter_images), i + 1)
    plt.imshow(letter_images[i], cmap='gray')
plt.show()

# 匹配車牌文字 Matching License Plate Number
results = []
for index, letter_image in enumerate(letter_images):
    best_score = []
    patterns = os.listdir(patternsPath)
    for filename in patterns:  # 讀取資料夾下所有的圖片
        ret, pattern_img = cv2.threshold(cv2.cvtColor(cv2.imdecode(np.fromfile(patternsPath + filename, dtype=np.uint8), 1), cv2.COLOR_RGB2GRAY), 0, 255, cv2.THRESH_OTSU)  # 將範本進行格式轉換，再獲得Binary圖
        pattern_img = cv2.resize(pattern_img, (letter_image.shape[1], letter_image.shape[0]))  # 將範本resize至與圖像一樣大小
        best_score.append(cv2.matchTemplate(letter_image, pattern_img, cv2.TM_CCOEFF)[0][0])  # 範本匹配，返回匹配得分
    i = best_score.index(max(best_score))  # 取得最高分的index
    results.append(patterns[i])
license_plate_number = "".join(results).replace(extension, "")  # Printing Rusults To Console
print("辨識到的車牌號碼:", license_plate_number)

# 查詢車主資料
try:
    with open("car_owners.csv", mode="r", encoding="utf-8-sig") as file:  # 確保 utf-8-sig 避免 Excel 轉存問題
        reader = csv.DictReader(file)

        # ✅ 先檢查標題是否正確
        headers = [col.strip() for col in reader.fieldnames]
        print("讀取到的標題欄位:", headers)

        # ✅ 確保標題名稱是正確的
        if "車牌號碼" not in headers or "車主姓名" not in headers:
            print("❌ CSV 標題欄位名稱不正確，請確認檔案內容！")
        else:
            found = False
            for row in reader:  # 讀取每一行
                if row["車牌號碼"].strip() == license_plate_number:  # 確保比較時去除空格
                    print("✅ 車主姓名:", row["車主姓名"])
                    found = True
                    break

            if not found:
                print("❌ 車主資料未找到。")
except FileNotFoundError:
    print("資料庫檔案未找到。")

# 安裝 OpenCV（適用於 Colab 的 headless 版本）
!pip install opencv-python-headless

# 安裝 NumPy
!pip install numpy

# 安裝 Matplotlib
!pip install matplotlib

import os
import cv2
import numpy as np
import csv
import time
from matplotlib import pyplot as plt
from datetime import datetime

# 配置變數
extension = '.jpg'
patternsPath = 'solid_patterns/'
databasePath = 'car_owners.csv'

def extract_and_recognize_chars(plate_image, patterns_path):
    # 獲取字符輪廓
    contours, hierarchy = cv2.findContours(plate_image, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)
    letters = []

    # 過濾和提取字符
    for contour in contours:
        rect = cv2.boundingRect(contour)
        if (rect[3] > (rect[2] * 1.5)) and (rect[3] < (rect[2] * 3.5) and (rect[2] > 10)):
            letters.append(rect)

    # 排序並提取字符圖像
    letter_images = []
    for letter in sorted(letters, key=lambda s: s[0]):
        x, y, w, h = letter
        letter_images.append(plate_image[y:y+h, x:x+w])

    # 識別字符
    results = []
    for letter_image in letter_images:
        best_score = []
        patterns = os.listdir(patterns_path)

        for filename in patterns:
            pattern_img = cv2.imdecode(np.fromfile(os.path.join(patterns_path, filename), dtype=np.uint8), 1)
            pattern_gray = cv2.cvtColor(pattern_img, cv2.COLOR_RGB2GRAY)
            _, pattern_binary = cv2.threshold(pattern_gray, 0, 255, cv2.THRESH_OTSU)
            pattern_resized = cv2.resize(pattern_binary, (letter_image.shape[1], letter_image.shape[0]))

            score = cv2.matchTemplate(letter_image, pattern_resized, cv2.TM_CCOEFF)[0][0]
            best_score.append(score)

        if best_score:
            best_match = patterns[best_score.index(max(best_score))]
            results.append(best_match.replace(extension, ''))

    return ''.join(results) if results else None

def process_frame(frame, patterns_path):
    try:
        # 轉換顏色空間
        frame_bgr = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)

        # 車牌檢測
        gray = cv2.cvtColor(frame_bgr, cv2.COLOR_BGR2GRAY)
        denoised = cv2.bilateralFilter(gray, 11, 17, 17)
        blurred = cv2.GaussianBlur(denoised, (5, 5), 0)
        edges = cv2.Canny(blurred, 170, 200)
        contours, _ = cv2.findContours(edges, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)

        # 尋找可能的車牌區域
        for contour in sorted(contours, key=cv2.contourArea, reverse=True)[:30]:
            approx = cv2.approxPolyDP(contour, 0.02 * cv2.arcLength(contour, True), True)
            if len(approx) == 4:
                x, y, w, h = cv2.boundingRect(contour)

                # 檢查區域大小是否合理（避免誤檢）
                if w < 60 or h < 20:  # 太小的區域跳過
                    continue

                # 檢查長寬比是否符合車牌特徵
                aspect_ratio = float(w) / h
                if not (2.0 <= aspect_ratio <= 5.5):  # 車牌的典型長寬比範圍
                    continue

                # 繪製檢測框
                cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)

                # 提取車牌區域
                plate_region = frame_bgr[y:y + h, x:x + w]
                if plate_region.size == 0:
                    continue

                # 處理車牌圖像
                _, plate_binary = cv2.threshold(
                    cv2.cvtColor(
                        cv2.GaussianBlur(plate_region, (3, 3), 0),
                        cv2.COLOR_RGB2GRAY
                    ),
                    0, 255, cv2.THRESH_OTSU
                )

                # 提取字符
                plate_number = extract_and_recognize_chars(plate_binary, patterns_path)
                if plate_number:
                    # 在畫面上顯示車牌號碼
                    cv2.putText(
                        frame,
                        f"車牌: {plate_number}",
                        (x, y - 10),
                        cv2.FONT_HERSHEY_SIMPLEX,
                        0.7,
                        (0, 255, 0),
                        2
                    )
                    return frame, plate_number

        return frame, None
    except Exception as e:
        print(f"處理幀時發生錯誤: {str(e)}")
        return frame, None

def start_camera_recognition():
    # 添加視窗設置
    cv2.namedWindow('License Plate Recognition', cv2.WINDOW_NORMAL)
    cv2.resizeWindow('License Plate Recognition', 1280, 720)

    cap = cv2.VideoCapture(0)
    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1920)
    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 1080)

    if not cap.isOpened():
        print("無法開啟攝像頭")
        return

    last_recognition_time = 0
    recognition_cooldown = 2

    try:
        while True:
            ret, frame = cap.read()
            if not ret:
                print("無法讀取攝像頭畫面")
                break

            # 添加幀率顯示
            fps = cap.get(cv2.CAP_PROP_FPS)
            cv2.putText(frame, f"FPS: {int(fps)}", (10, 30),
                       cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)

            current_time = time.time()

            if current_time - last_recognition_time >= recognition_cooldown:
                processed_frame, plate_number = process_frame(frame, patternsPath)

                if plate_number:
                    last_recognition_time = current_time
                    try:
                        with open(databasePath, mode="r", encoding="utf-8-sig") as file:
                            reader = csv.DictReader(file)
                            for row in reader:
                                if row["車牌號碼"].strip() == plate_number:
                                    info = f"""
時間: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
車牌號碼: {plate_number}
車主姓名: {row['車主姓名']}
{'='*30}"""
                                    print(info)
                                    break
                    except FileNotFoundError:
                        print("無法讀取資料庫文件")
            else:
                processed_frame = frame

            cv2.imshow('License Plate Recognition', processed_frame)

            if cv2.waitKey(1) & 0xFF == ord('q'):
                break

    finally:
        cap.release()
        cv2.destroyAllWindows()

if __name__ == "__main__":
    start_camera_recognition()

import os
import shutil

base_dir = 'dataset'
for filename in os.listdir(base_dir):
    if filename.endswith('.jpg'):
        label = filename.split('.')[0]  # e.g., "0" from "0.jpg"
        label_dir = os.path.join(base_dir, label)
        os.makedirs(label_dir, exist_ok=True)
        src = os.path.join(base_dir, filename)
        dst = os.path.join(label_dir, filename)
        shutil.move(src, dst)

print("✅ 資料已自動分類完畢！")

#訓練
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense

IMG_SIZE = (32, 32)  # 每張圖會被縮成 32x32 像素

# 建立資料增強器與資料讀取器
datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)

train_generator = datagen.flow_from_directory(
    'dataset/',
    target_size=IMG_SIZE,
    color_mode='grayscale',
    batch_size=32,
    class_mode='categorical',
    subset='training'
)

val_generator = datagen.flow_from_directory(
    'dataset/',
    target_size=IMG_SIZE,
    color_mode='grayscale',
    batch_size=32,
    class_mode='categorical',
    subset='validation'
)

# 建構 CNN 模型
model = Sequential([
    Conv2D(32, (3, 3), activation='relu', input_shape=(IMG_SIZE[0], IMG_SIZE[1], 1)),
    MaxPooling2D(2, 2),
    Conv2D(64, (3, 3), activation='relu'),
    MaxPooling2D(2, 2),
    Flatten(),
    Dense(128, activation='relu'),
    Dense(36, activation='softmax')  # 假設你有 0~9 和 A~Z，共36類
])

model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

num_classes = train_generator.num_classes  # 自動抓資料夾裡的分類數

model = Sequential([
    Conv2D(32, (3, 3), activation='relu', input_shape=(64, 64, 3)),
    MaxPooling2D(2, 2),
    Flatten(),
    Dense(128, activation='relu'),
    Dense(num_classes, activation='softmax')  # ✅ 自動適配分類數
])

#重啟google drive
from google.colab import drive
drive.mount('/content/drive', force_remount=True)

import os
import numpy as np
from concurrent.futures import ThreadPoolExecutor
from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array
from tqdm import tqdm

def create_image_generator():
    """創建並返回配置好的圖片增強器"""
    return ImageDataGenerator(
        rotation_range=20,  # 降低旋轉角度使圖片更自然
        width_shift_range=0.15,
        height_shift_range=0.15,
        shear_range=0.15,
        zoom_range=0.15,
        horizontal_flip=True,
        fill_mode='nearest',
        brightness_range=[0.8, 1.2],  # 添加亮度調整
        rescale=1./255  # 歸一化處理
    )

def is_valid_image(filename):
    """檢查文件是否為有效的圖片格式"""
    valid_extensions = {'.jpg', '.jpeg', '.png', '.bmp'}
    return os.path.splitext(filename.lower())[1] in valid_extensions

def process_single_class(args):
    """處理單個類別的圖片增強"""
    directory, class_name, num_augmented_images = args
    class_folder = os.path.join(directory, class_name)

    if not os.path.isdir(class_folder):
        print(f"警告: {class_folder} 不是有效的目錄，跳過處理")
        return

    # 獲取所有有效的圖片文件
    image_files = [f for f in os.listdir(class_folder) if is_valid_image(f)]
    if not image_files:
        print(f"警告: {class_folder} 中沒有有效的圖片文件，跳過處理")
        return

    datagen = create_image_generator()

    for image_file in image_files:
        try:
            image_path = os.path.join(class_folder, image_file)
            # 讀取並預處理圖片
            img = load_img(image_path, target_size=(224, 224))  # 將圖片縮放為固定大小
            x = img_to_array(img)
            x = np.expand_dims(x, axis=0)

            # 生成增強圖片
            i = 0
            for batch in datagen.flow(
                x,
                batch_size=1,
                save_to_dir=class_folder,
                save_prefix=f'{class_name}_aug',
                save_format='jpg'
            ):
                i += 1
                if i >= num_augmented_images:
                    break

        except Exception as e:
            print(f"處理圖片 {image_path} 時發生錯誤: {str(e)}")
            continue

def augment_images_for_directory(directory, num_augmented_images=10, max_workers=2):
    """使用多線程處理目錄中的所有類別"""
    try:
        if not os.path.exists(directory):
            raise FileNotFoundError(f"目錄不存在: {directory}")

        # 獲取所有類別目錄
        class_names = [d for d in os.listdir(directory)
                      if os.path.isdir(os.path.join(directory, d))]

        if not class_names:
            raise ValueError(f"在 {directory} 中沒有找到任何子目錄")

        print(f"\n開始處理目錄: {directory}")
        print(f"找到 {len(class_names)} 個類別目錄")

        # 準備參數
        args_list = [(directory, class_name, num_augmented_images)
                     for class_name in class_names]

        # 使用線程池並行處理
        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            list(tqdm(executor.map(process_single_class, args_list),
                     total=len(args_list),
                     desc="處理進度"))

    except Exception as e:
        print(f"處理目錄 {directory} 時發生錯誤: {str(e)}")

def main():
    # 設定資料夾路徑
    train_dir = '/content/drive/MyDrive/model_training/dataset/train'
    val_dir = '/content/drive/MyDrive/model_training/dataset/validation'

    try:
        print("開始圖片增強處理...")

        # 處理訓練集
        augment_images_for_directory(train_dir, num_augmented_images=10, max_workers=2)

        # 處理驗證集
        augment_images_for_directory(val_dir, num_augmented_images=10, max_workers=2)

        print("\n✅ 圖片增強完成！")

    except Exception as e:
        print(f"程式執行過程中發生錯誤: {str(e)}")

if __name__ == '__main__':
    main()

import os
import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, CSVLogger, TensorBoard
from tensorflow.keras.applications import ResNet50
from tensorflow.keras.layers import Dense, GlobalAveragePooling2D
from tensorflow.keras.models import Model
from google.colab import drive

# 掛載Google Drive
drive.mount('/content/drive')

# 檢查是否有可用的GPU
print("Num GPUs Available: ", len(tf.config.list_physical_devices('GPU')))

# 設置工作目錄
base_dir = '/content/drive/MyDrive/model_training'
os.makedirs(base_dir, exist_ok=True)

# 創建必要的目錄
checkpoint_dir = os.path.join(base_dir, 'checkpoints')#checkpoints：儲存最佳模型。
log_dir = os.path.join(base_dir, 'logs')#logs：儲存訓練過程記錄。
dataset_dir = os.path.join(base_dir, 'dataset')#dataset：訓練與驗證圖片資料夾。
os.makedirs(checkpoint_dir, exist_ok=True)
os.makedirs(log_dir, exist_ok=True)
os.makedirs(dataset_dir, exist_ok=True)

# 設置數據增強和預處理
train_datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    horizontal_flip=True,
    fill_mode='nearest'
)#對訓練資料做影像增強（旋轉、平移、翻轉等），提高模型泛化能力。

#驗證資料僅縮放（rescale=1./255），不做其他增強。

val_datagen = ImageDataGenerator(rescale=1./255)

# 加載數據集
train_generator = train_datagen.flow_from_directory(
    os.path.join(dataset_dir, 'train'),
    target_size=(224, 224),
    batch_size=32,
    class_mode='categorical'
)

val_generator = val_datagen.flow_from_directory(
    os.path.join(dataset_dir, 'validation'),
    target_size=(224, 224),
    batch_size=32,
    class_mode='categorical'
)

# 創建模型
base_model = ResNet50(weights='imagenet', include_top=False)
x = base_model.output
x = GlobalAveragePooling2D()(x)
x = Dense(1024, activation='relu')(x)
predictions = Dense(train_generator.num_classes, activation='softmax')(x)
model = Model(inputs=base_model.input, outputs=predictions)

# 編譯模型
model.compile(
    optimizer='adam',  # 使用 Adam 優化器
    loss='categorical_crossentropy',  # 目標是多分類問題
    metrics=['accuracy']  # 評估指標使用準確度
)

# 設置回調函數
checkpoint = ModelCheckpoint(
    filepath=os.path.join(checkpoint_dir, 'model_best.h5'),
    monitor='val_loss',
    save_best_only=True,
    mode='min',
    verbose=1
)

early_stopping = EarlyStopping(
    monitor='val_loss',
    patience=3,
    restore_best_weights=True,
    verbose=1
)

csv_logger = CSVLogger(
    os.path.join(log_dir, 'training_history.csv'),
    separator=',',
    append=False
)

tensorboard = TensorBoard(
    log_dir=os.path.join(log_dir, 'tensorboard'),
    histogram_freq=1,
    write_graph=True
)

# 開始訓練模型
history = model.fit(
    train_generator,
    epochs=1,
    validation_data=val_generator,
    callbacks=[checkpoint, early_stopping, csv_logger, tensorboard],
    verbose=1
)

#訓練-2
import os
import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, CSVLogger, TensorBoard, ReduceLROnPlateau
from tensorflow.keras.applications import ResNet50
from tensorflow.keras.layers import Dense, GlobalAveragePooling2D
from tensorflow.keras.models import Model
from google.colab import drive

# 掛載Google Drive
drive.mount('/content/drive')

# 檢查是否有可用的GPU
print("Num GPUs Available: ", len(tf.config.list_physical_devices('GPU')))

# 設置工作目錄
base_dir = '/content/drive/MyDrive/model_training'
checkpoint_dir = os.path.join(base_dir, 'checkpoints')
log_dir = os.path.join(base_dir, 'logs')
dataset_dir = os.path.join(base_dir, 'dataset')
os.makedirs(checkpoint_dir, exist_ok=True)
os.makedirs(log_dir, exist_ok=True)
os.makedirs(dataset_dir, exist_ok=True)

# 數據增強與前處理
train_datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    horizontal_flip=True,
    fill_mode='nearest'
)

val_datagen = ImageDataGenerator(rescale=1./255)

# 載入訓練與驗證資料
train_generator = train_datagen.flow_from_directory(
    os.path.join(dataset_dir, 'train'),
    target_size=(224, 224),
    batch_size=32,
    class_mode='categorical'
)

val_generator = val_datagen.flow_from_directory(
    os.path.join(dataset_dir, 'validation'),
    target_size=(224, 224),
    batch_size=32,
    class_mode='categorical'
)

# 建立模型
base_model = ResNet50(weights='imagenet', include_top=False)
x = base_model.output
x = GlobalAveragePooling2D()(x)
x = Dense(1024, activation='relu')(x)
predictions = Dense(train_generator.num_classes, activation='softmax')(x)
model = Model(inputs=base_model.input, outputs=predictions)

# 編譯模型
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

# ReduceLROnPlateau：當 val_loss 停滯不前時降低學習率
reduce_lr = ReduceLROnPlateau(
    monitor='val_loss',
    factor=0.5,
    patience=3,
    min_lr=1e-6,
    verbose=1
)

# 回調函數設置
checkpoint = ModelCheckpoint(
    filepath=os.path.join(checkpoint_dir, 'model_best.h5'),
    monitor='val_loss',
    save_best_only=True,
    mode='min',
    verbose=1
)

early_stopping = EarlyStopping(
    monitor='val_loss',
    patience=8,
    restore_best_weights=True,
    verbose=1
)

csv_logger = CSVLogger(os.path.join(log_dir, 'training_history.csv'), separator=',', append=False)

tensorboard = TensorBoard(log_dir=os.path.join(log_dir, 'tensorboard'), histogram_freq=1, write_graph=True)

# 訓練模型
history = model.fit(
    train_generator,
    epochs=50,
    validation_data=val_generator,
    callbacks=[checkpoint, early_stopping, csv_logger, tensorboard, reduce_lr],
    verbose=1
)

# 儲存最終模型
model.save(os.path.join(checkpoint_dir, 'model_final.h5'))
print("訓練完成！模型已儲存。")

#訓練-3
# 訓練 - 改善過擬合版本
import os
import tensorflow as tf
import matplotlib.pyplot as plt
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, CSVLogger, TensorBoard, ReduceLROnPlateau
from tensorflow.keras.applications import ResNet50
from tensorflow.keras.layers import Dense, GlobalAveragePooling2D
from tensorflow.keras.models import Model
from tensorflow.keras.optimizers import Adam
from google.colab import drive

# 掛載 Google Drive
drive.mount('/content/drive')

# GPU 檢查
print("Num GPUs Available: ", len(tf.config.list_physical_devices('GPU')))

# 目錄設定
base_dir = '/content/drive/MyDrive/model_training'
checkpoint_dir = os.path.join(base_dir, 'checkpoints')
log_dir = os.path.join(base_dir, 'logs')
dataset_dir = os.path.join(base_dir, 'dataset')
os.makedirs(checkpoint_dir, exist_ok=True)
os.makedirs(log_dir, exist_ok=True)
os.makedirs(dataset_dir, exist_ok=True)

# 資料增強
train_datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    horizontal_flip=True,
    fill_mode='nearest'
)
val_datagen = ImageDataGenerator(rescale=1./255)

# 載入資料
train_generator = train_datagen.flow_from_directory(
    os.path.join(dataset_dir, 'train'),
    target_size=(224, 224),
    batch_size=32,
    class_mode='categorical'
)
val_generator = val_datagen.flow_from_directory(
    os.path.join(dataset_dir, 'validation'),
    target_size=(224, 224),
    batch_size=32,
    class_mode='categorical'
)

# 建立模型
base_model = ResNet50(weights='imagenet', include_top=False)
for layer in base_model.layers:
    layer.trainable = False  # 凍結 ResNet50 卷積層

x = base_model.output
x = GlobalAveragePooling2D()(x)
x = Dense(1024, activation='relu')(x)
predictions = Dense(train_generator.num_classes, activation='softmax')(x)
model = Model(inputs=base_model.input, outputs=predictions)

# 編譯模型（較小學習率）
model.compile(optimizer=Adam(learning_rate=1e-4),
              loss='categorical_crossentropy',
              metrics=['accuracy'])

# 回調函數
checkpoint = ModelCheckpoint(
    filepath=os.path.join(checkpoint_dir, 'model_best.h5'),
    monitor='val_loss',
    save_best_only=True,
    mode='min',
    verbose=1
)

early_stopping = EarlyStopping(
    monitor='val_loss',
    patience=5,
    restore_best_weights=True,
    verbose=1
)

reduce_lr = ReduceLROnPlateau(
    monitor='val_loss',
    factor=0.5,
    patience=2,
    min_lr=1e-6,
    verbose=1
)

csv_logger = CSVLogger(os.path.join(log_dir, 'training_history.csv'), separator=',', append=False)

tensorboard = TensorBoard(log_dir=os.path.join(log_dir, 'tensorboard'), histogram_freq=1)

# 開始訓練
history = model.fit(
    train_generator,
    epochs=30,
    validation_data=val_generator,
    callbacks=[checkpoint, early_stopping, csv_logger, tensorboard, reduce_lr],
    verbose=1
)

# 儲存最終模型
model.save(os.path.join(checkpoint_dir, 'model_final.h5'))
print("訓練完成！模型已儲存。")

# 視覺化訓練結果
plt.plot(history.history['accuracy'], label='Train Accuracy')
plt.plot(history.history['val_accuracy'], label='Val Accuracy')
plt.title('Model Accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend()
plt.grid(True)
plt.show()

plt.plot(history.history['loss'], label='Train Loss')
plt.plot(history.history['val_loss'], label='Val Loss')
plt.title('Model Loss')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend()
plt.grid(True)
plt.show()

history = model.fit(
    train_generator,  # 訓練資料生成器，提供訓練數據
    epochs=10,  # 訓練的總輪數（Epochs），在每一輪中，模型將遍歷整個訓練資料集
    validation_data=val_generator,  # 驗證資料生成器，提供驗證數據，用於評估模型在每一輪的表現
    callbacks=[checkpoint, early_stopping, csv_logger, tensorboard],  # 使用的回調函數列表
    verbose=1  # 訓練過程的顯示模式，1表示進度條顯示，0表示不顯示
)

# 輸出訓練過程中的結果
print("Training History:", history.history)

csv_logger = CSVLogger('training_log.csv', append=True)  # 創建 CSVLogger 回調函數，將訓練過程記錄到 CSV 文件

history = model.fit(
    train_generator,
    epochs=10,
    validation_data=val_generator,
    callbacks=[csv_logger],  # 這裡將 CSVLogger 加入回調函數
    verbose=1
)

import matplotlib.pyplot as plt  # 引入matplotlib庫，用於繪製圖表

# 繪製訓練和驗證損失
plt.plot(history.history['loss'], label='Training Loss')  # 繪製訓練損失曲線
plt.plot(history.history['val_loss'], label='Validation Loss')  # 繪製驗證損失曲線
plt.title('Training and Validation Loss')  # 圖表標題
plt.xlabel('Epochs')  # x 軸標籤，表示訓練的輪數
plt.ylabel('Loss')  # y 軸標籤，表示損失值
plt.legend()  # 顯示圖例，區分訓練和驗證損失
plt.show()  # 顯示圖表

# 繪製訓練和驗證準確度
plt.plot(history.history['accuracy'], label='Training Accuracy')  # 繪製訓練準確度曲線
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')  # 繪製驗證準確度曲線
plt.title('Training and Validation Accuracy')  # 圖表標題
plt.xlabel('Epochs')  # x 軸標籤
plt.ylabel('Accuracy')  # y 軸標籤，表示準確度
plt.legend()  # 顯示圖例
plt.show()  # 顯示圖表

plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.title('Training and Validation Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.savefig('loss_plot.png')  # 保存為名為 loss_plot.png 的圖像文件

plt.plot(history.history['accuracy'], label='Training Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.title('Training and Validation Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()
plt.savefig('accuracy_plot.png')  # 保存為名為 accuracy_plot.png 的圖像文件